{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in ./.local/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.local/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in ./.local/lib/python3.10/site-packages (from scikit-learn) (1.21.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.local/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/lib/python3/dist-packages (from scikit-learn) (1.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: num2words in ./.local/lib/python3.10/site-packages (0.5.12)\n",
      "Requirement already satisfied: docopt>=0.6.2 in ./.local/lib/python3.10/site-packages (from num2words) (0.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T02:58:32.305185Z",
     "start_time": "2023-05-14T02:58:30.152562Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import torch\n",
    "import requests\n",
    "import json\n",
    "from nltk.corpus import brown\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import io\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "import json\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "import requests\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "import num2words\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import num2words\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download SQuAD2 dataset\n",
    "url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\"\n",
    "response = requests.get(url)\n",
    "\n",
    "#Save the dataset to a file\n",
    "dataset_file = \"squad2.json\"\n",
    "with open(dataset_file, 'wb') as f:\n",
    "   f.write(response.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ubtadobres/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T02:59:23.405379Z",
     "start_time": "2023-05-14T02:59:23.382743Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#We will use this function on each file in the dataset - test and train\n",
    "#only the filename is required as the previous function returns the specified file to the same location\n",
    "\n",
    "def extract_squad_data(file_name):\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        file_name = json.load(f)\n",
    "\n",
    "    paragraphs = []\n",
    "    for article in file_name['data']:\n",
    "        for paragraph in article['paragraphs']:\n",
    "            for qa in paragraph['qas']:\n",
    "                question = qa['question']\n",
    "                answers = [answer['text'] for answer in qa['answers']]\n",
    "                for answer in answers:\n",
    "                    paragraphs.append((question, answer))\n",
    "\n",
    "    df = pd.DataFrame(paragraphs, columns=['Question', 'Answer'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T02:59:25.715029Z",
     "start_time": "2023-05-14T02:59:24.424164Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#convert .json files to dataframes\n",
    "squad_df = extract_squad_data(\"squad2.json\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_word_histogram_side_by_side(dataframe, question_column, answer_column, title):\n",
    "    # Combine all the words from the question_column into a single string\n",
    "    all_question_words = ' '.join(dataframe[question_column].values.tolist())\n",
    "\n",
    "    # Split the string into individual words for the question_column\n",
    "    question_word_list = all_question_words.split()\n",
    "\n",
    "    # Combine all the words from the answer_column into a single string\n",
    "    all_answer_words = ' '.join(dataframe[answer_column].values.tolist())\n",
    "\n",
    "    # Split the string into individual words for the answer_column\n",
    "    answer_word_list = all_answer_words.split()\n",
    "\n",
    "    # Count the frequency of each word for the question_column\n",
    "    question_word_counts = {}\n",
    "    for word in question_word_list:\n",
    "        question_word_counts[word] = question_word_counts.get(word, 0) + 1\n",
    "\n",
    "    # Count the frequency of each word for the answer_column\n",
    "    answer_word_counts = {}\n",
    "    for word in answer_word_list:\n",
    "        answer_word_counts[word] = answer_word_counts.get(word, 0) + 1\n",
    "\n",
    "    # Calculate the frequency buckets for the question_column\n",
    "    question_bucket_counts = [0] * 10\n",
    "    for count in question_word_counts.values():\n",
    "        if count < 5:\n",
    "            question_bucket_counts[0] += 1\n",
    "        elif count < 10:\n",
    "            question_bucket_counts[1] += 1\n",
    "        elif count < 15:\n",
    "            question_bucket_counts[2] += 1\n",
    "        elif count < 20:\n",
    "            question_bucket_counts[3] += 1\n",
    "        elif count < 25:\n",
    "            question_bucket_counts[4] += 1\n",
    "        elif count < 30:\n",
    "            question_bucket_counts[5] += 1\n",
    "        elif count < 35:\n",
    "            question_bucket_counts[6] += 1\n",
    "        elif count < 40:\n",
    "            question_bucket_counts[7] += 1\n",
    "        elif count < 45:\n",
    "            question_bucket_counts[8] += 1\n",
    "        else:\n",
    "            question_bucket_counts[9] += 1\n",
    "\n",
    "    # Calculate the frequency buckets for the answer_column\n",
    "    answer_bucket_counts = [0] * 10\n",
    "    for count in answer_word_counts.values():\n",
    "        if count < 5:\n",
    "            answer_bucket_counts[0] += 1\n",
    "        elif count < 10:\n",
    "            answer_bucket_counts[1] += 1\n",
    "        elif count < 15:\n",
    "            answer_bucket_counts[2] += 1\n",
    "        elif count < 20:\n",
    "            answer_bucket_counts[3] += 1\n",
    "        elif count < 25:\n",
    "            answer_bucket_counts[4] += 1\n",
    "        elif count < 30:\n",
    "            answer_bucket_counts[5] += 1\n",
    "        elif count < 35:\n",
    "            answer_bucket_counts[6] += 1\n",
    "        elif count < 40:\n",
    "            answer_bucket_counts[7] += 1\n",
    "        elif count < 45:\n",
    "            answer_bucket_counts[8] += 1\n",
    "        else:\n",
    "            answer_bucket_counts[9] += 1\n",
    "\n",
    "    # Calculate the total word count (Question + Answer)\n",
    "    total_word_list = question_word_list + answer_word_list\n",
    "    total_word_count = len(total_word_list)\n",
    "\n",
    "    # Set the width of the bars\n",
    "    bar_width = 0.35\n",
    "\n",
    "    # Set the x locations of the bars\n",
    "    r1 = np.arange(len(question_bucket_counts))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "\n",
    "    # Plot the histogram side by side\n",
    "    plt.bar(r1, question_bucket_counts, color='b', width=bar_width, label=f'{question_column}')\n",
    "    plt.bar(r2, answer_bucket_counts, color='orange', width=bar_width, label=f'{answer_column}')\n",
    "\n",
    "    # Add a separate box/call out for total word count\n",
    "    plt.text(len(question_bucket_counts) / 2, max(max(question_bucket_counts), max(answer_bucket_counts)),\n",
    "             f'Total Words: {total_word_count}', ha='center', va='center', bbox=dict(facecolor='lightgray', edgecolor='black', boxstyle='round'))\n",
    "\n",
    "    # Add labels, title, and legend\n",
    "    plt.xlabel('Frequency Range')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(title)\n",
    "    plt.xticks([r + bar_width/2 for r in range(len(question_bucket_counts))], ['0-4', '5-9', '10-14', '15-19', '20-24',\n",
    "                                                                        '25-29', '30-34', '35-39', '40-44', '45+'])\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_word_histogram_side_by_side(squad_df, 'Question', 'Answer', 'Word frequency comparision for raw data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This Histogram shows the vast majority of the words appearly very infreqently. \n",
    "# This may negantivitly affect performance as such frequnctly appearing words may have little informational value and act as noise \n",
    "# Hence data the data cleaning below (ext cleaning, tokenising, removing stopwords, removing rare words (<2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Vocab trg Raw\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0             When did Beyonce start becoming popular?\n",
      "1    What areas did Beyonce compete in when she was...\n",
      "2    When did Beyonce leave Destiny's Child and bec...\n",
      "3        In what city and state did Beyonce  grow up? \n",
      "4           In which decade did Beyonce become famous?\n",
      "Name: Question, dtype: object\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Testing Vocab src Raw\n",
      "0      in the late 1990s\n",
      "1    singing and dancing\n",
      "2                   2003\n",
      "3         Houston, Texas\n",
      "4             late 1990s\n",
      "Name: Answer, dtype: object\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "#sample of src/answer pairs for raw datat\n",
    "print(\"Training Vocab trg Raw\")\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(squad_df['Question'].head(5))\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"Testing Vocab src Raw\")\n",
    "print(squad_df['Answer'].head(5))\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#pre-cleaned questions and trg to list\\nraw_src = train_df['Question'].tolist()\\nraw_answers = train_df['Answer'].tolist()\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"#pre-cleaned questions and trg to list\n",
    "raw_src = train_df['Question'].tolist()\n",
    "raw_answers = train_df['Answer'].tolist()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text cleaning, tokenising, removing stopwords, removing rare words (<2)\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import SnowballStemmer\n",
    "from num2words import num2words\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = set(stopwords.words('english'))  # NLTK's list of English stop words\n",
    "\n",
    "def clean_text(df, min_freq=2):  # min_freq: minimum frequency to keep a token\n",
    "    cleaned_df = df.copy()\n",
    "    all_tokens = []  # List to store all tokens for frequency calculation\n",
    "    \n",
    "    for column in cleaned_df:\n",
    "        cleaned_df[column] = cleaned_df[column].apply(lambda sentence: process_sentence(sentence, all_tokens))\n",
    "        \n",
    "    # Create frequency distribution of tokens\n",
    "    freq_dist = FreqDist(all_tokens)\n",
    "    \n",
    "    # Identify rare tokens\n",
    "    rare_tokens = {token for token, freq in freq_dist.items() if freq < min_freq}\n",
    "    \n",
    "    # Remove rare tokens from the dataframe\n",
    "    for column in cleaned_df:\n",
    "        cleaned_df[column] = cleaned_df[column].apply(lambda sentence: ' '.join(token for token in sentence.split() if token not in rare_tokens))\n",
    "        \n",
    "    return cleaned_df\n",
    "\n",
    "def process_sentence(sentence, all_tokens):\n",
    "    sentence = ''.join([s.lower() for s in sentence if s not in string.punctuation])\n",
    "    sentence = ' '.join(stemmer.stem(w) for w in sentence.split())\n",
    "    \n",
    "    # Convert numbers to words\n",
    "    sentence = ' '.join(convert_num_to_words(w) for w in sentence.split())\n",
    "    \n",
    "    # Remove stop words\n",
    "    sentence = ' '.join(w for w in sentence.split() if w not in stop_words)\n",
    "    \n",
    "    tokens = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(sentence)\n",
    "    \n",
    "    # Add tokens to the all_tokens list\n",
    "    all_tokens.extend(tokens)\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def convert_num_to_words(s):\n",
    "    try:\n",
    "        # Remove comma from numbers\n",
    "        s = s.replace(',', '')\n",
    "        # If the string represents a fraction, convert both parts separately\n",
    "        if '/' in s:\n",
    "            numerator, denominator = s.split('/')\n",
    "            return num2words(int(numerator)) + ' over ' + num2words(int(denominator))\n",
    "        # Otherwise, try converting the string to an integer or a float\n",
    "        try:\n",
    "            return num2words(int(s))\n",
    "        except ValueError:\n",
    "            return num2words(float(s))\n",
    "    except:\n",
    "        # If any of the above attempts throw an exception, the string is not a number\n",
    "        return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean raw data files\n",
    "squad_clean_df = clean_text(squad_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Histrograme of word fequency for cleaned data\n",
    "plot_word_histogram_side_by_side(squad_clean_df, 'Question', 'Answer', 'Question/Answer Word frequency comparision for Cleaned data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A significant number of words have been removed, especally those in the 0-4 class. \n",
    "# This is to be expected since we removed all words with a frequency of less than 2 and all stop words (that tend to have a frequency of 4 or less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Vocab Answers Cleaned\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "0                     beyonc start becom popular\n",
      "1                        area beyonc compet grow\n",
      "2    beyonc leav destini child becom solo singer\n",
      "3                         citi state beyonc grow\n",
      "4                      decad beyonc becom famous\n",
      "Name: Question, dtype: object\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Testing Vocab src Cleaned\n",
      "0            late 1990s\n",
      "1             sing danc\n",
      "2    two thousand three\n",
      "3          houston texa\n",
      "4            late 1990s\n",
      "Name: Answer, dtype: object\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Vocab Answers Cleaned\")\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(squad_clean_df['Question'].head(5))\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "print(\"Testing Vocab src Cleaned\")\n",
    "print(squad_clean_df['Answer'].head(5))\n",
    "print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocab class that builds vocab, checks for unquie words, and assigns to an index value\n",
    "class Vocab:\n",
    "    def __init__(self):\n",
    "        self.word2index = {}\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
    "        self.word2count = {}\n",
    "        self.n_words = 4  # Count <PAD>, <SOS>, <EOS>, <UNK>\n",
    "\n",
    "    def build_vocab(self, sentences):\n",
    "        unique_words = set()\n",
    "        for sentence in sentences:\n",
    "            for word in self.tokenize(sentence):\n",
    "                unique_words.add(word)\n",
    "\n",
    "        for word in unique_words:\n",
    "            self.add_word(word)\n",
    "\n",
    "    def tokenize(self, sentence):\n",
    "        return sentence.strip().split()\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.word2count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = squad_clean_df['Question']\n",
    "answers = squad_clean_df['Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned question/answer pairs to Vocab\n",
    "question_vocab = Vocab()\n",
    "answer_vocab = Vocab()\n",
    "\n",
    "\n",
    "question_vocab.build_vocab(questions)\n",
    "answer_vocab.build_vocab(answers)\n",
    "\n",
    "question_vocab.add_word('<UNK>')\n",
    "answer_vocab.add_word('<UNK>')\n",
    "\n",
    "# Define and build your vocabularies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19385\n"
     ]
    }
   ],
   "source": [
    "print(question_vocab.n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set, question Vocab size in unique tokens\n",
      "19381\n",
      "#############################################\n",
      "Training Set, Answer Vocab size in unique tokens\n",
      "19261\n"
     ]
    }
   ],
   "source": [
    "#counting vocab sizes\n",
    "print(\"Training Set, question Vocab size in unique tokens\")\n",
    "question_vocab_size = len(question_vocab.word2count)\n",
    "print(question_vocab_size)\n",
    "\n",
    "print(\"#############################################\")\n",
    "\n",
    "print(\"Training Set, Answer Vocab size in unique tokens\")\n",
    "answer_vocab_size = len(answer_vocab.word2count)\n",
    "print(answer_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_cut(df, column_names, length):\n",
    "    pad_symbol = \"<PAD>\"\n",
    "    \n",
    "    for column_name in column_names:\n",
    "        df[column_name] = df[column_name].apply(lambda x: (x.split()[:length] + [pad_symbol]*length)[:length])\n",
    "        df[column_name] = df[column_name].apply(lambda x: ' '.join(x))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "padded_df = pad_or_cut(squad_clean_df, ['Question', 'Answer'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_indices(df, question_vocab, answer_vocab):\n",
    "    df['Question'] = df['Question'].apply(lambda sentence: [question_vocab.word2index[word] if word in question_vocab.word2index else question_vocab.word2index['<UNK>'] for word in sentence.split()])\n",
    "    df['Answer'] = df['Answer'].apply(lambda sentence: [answer_vocab.word2index[word] if word in answer_vocab.word2index else answer_vocab.word2index['<UNK>'] for word in sentence.split()])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_df = words_to_indices(padded_df, question_vocab, answer_vocab) # could have used nn.padding & nn.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_df_save = idx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3101, 1166, 3251, 9115, 19384, 19384, 19384, ...</td>\n",
       "      <td>[2117, 12266, 19264, 19264, 19264, 19264, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10446, 3101, 9565, 5034, 19384, 19384, 19384,...</td>\n",
       "      <td>[4993, 11945, 19264, 19264, 19264, 19264, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3101, 1142, 11151, 16884, 3251, 11176, 10684,...</td>\n",
       "      <td>[9011, 11312, 6628, 19264, 19264, 19264, 19264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[6069, 2830, 3101, 5034, 19384, 19384, 19384, ...</td>\n",
       "      <td>[14837, 10292, 19264, 19264, 19264, 19264, 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[7268, 3101, 3251, 15196, 19384, 19384, 19384,...</td>\n",
       "      <td>[2117, 12266, 19264, 19264, 19264, 19264, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86816</th>\n",
       "      <td>[8403, 2830, 6550, 9923, 18031, 5392, 1917, 19...</td>\n",
       "      <td>[10806, 19264, 19264, 19264, 19264, 19264, 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86817</th>\n",
       "      <td>[5563, 16508, 11002, 19384, 19384, 19384, 1938...</td>\n",
       "      <td>[4025, 19264, 19264, 19264, 19264, 19264, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86818</th>\n",
       "      <td>[6808, 6069, 4842, 6550, 1917, 19384, 19384, 1...</td>\n",
       "      <td>[19264, 19264, 19264, 19264, 19264, 19264, 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86819</th>\n",
       "      <td>[13838, 6550, 12192, 1813, 5392, 1917, 19384, ...</td>\n",
       "      <td>[1159, 11312, 12444, 5176, 3383, 2379, 19264, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86820</th>\n",
       "      <td>[3932, 1813, 19384, 19384, 19384, 19384, 19384...</td>\n",
       "      <td>[6513, 16717, 6027, 19264, 19264, 19264, 19264...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86821 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Question  \\\n",
       "0      [3101, 1166, 3251, 9115, 19384, 19384, 19384, ...   \n",
       "1      [10446, 3101, 9565, 5034, 19384, 19384, 19384,...   \n",
       "2      [3101, 1142, 11151, 16884, 3251, 11176, 10684,...   \n",
       "3      [6069, 2830, 3101, 5034, 19384, 19384, 19384, ...   \n",
       "4      [7268, 3101, 3251, 15196, 19384, 19384, 19384,...   \n",
       "...                                                  ...   \n",
       "86816  [8403, 2830, 6550, 9923, 18031, 5392, 1917, 19...   \n",
       "86817  [5563, 16508, 11002, 19384, 19384, 19384, 1938...   \n",
       "86818  [6808, 6069, 4842, 6550, 1917, 19384, 19384, 1...   \n",
       "86819  [13838, 6550, 12192, 1813, 5392, 1917, 19384, ...   \n",
       "86820  [3932, 1813, 19384, 19384, 19384, 19384, 19384...   \n",
       "\n",
       "                                                  Answer  \n",
       "0      [2117, 12266, 19264, 19264, 19264, 19264, 1926...  \n",
       "1      [4993, 11945, 19264, 19264, 19264, 19264, 1926...  \n",
       "2      [9011, 11312, 6628, 19264, 19264, 19264, 19264...  \n",
       "3      [14837, 10292, 19264, 19264, 19264, 19264, 192...  \n",
       "4      [2117, 12266, 19264, 19264, 19264, 19264, 1926...  \n",
       "...                                                  ...  \n",
       "86816  [10806, 19264, 19264, 19264, 19264, 19264, 192...  \n",
       "86817  [4025, 19264, 19264, 19264, 19264, 19264, 1926...  \n",
       "86818  [19264, 19264, 19264, 19264, 19264, 19264, 192...  \n",
       "86819  [1159, 11312, 12444, 5176, 3383, 2379, 19264, ...  \n",
       "86820  [6513, 16717, 6027, 19264, 19264, 19264, 19264...  \n",
       "\n",
       "[86821 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3101, 1166, 3251, 9115, 19384, 19384, 19384, ...</td>\n",
       "      <td>[2117, 12266, 19264, 19264, 19264, 19264, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10446, 3101, 9565, 5034, 19384, 19384, 19384,...</td>\n",
       "      <td>[4993, 11945, 19264, 19264, 19264, 19264, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[3101, 1142, 11151, 16884, 3251, 11176, 10684,...</td>\n",
       "      <td>[9011, 11312, 6628, 19264, 19264, 19264, 19264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[6069, 2830, 3101, 5034, 19384, 19384, 19384, ...</td>\n",
       "      <td>[14837, 10292, 19264, 19264, 19264, 19264, 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[7268, 3101, 3251, 15196, 19384, 19384, 19384,...</td>\n",
       "      <td>[2117, 12266, 19264, 19264, 19264, 19264, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[14936, 617, 18495, 10684, 19384, 19384, 19384...</td>\n",
       "      <td>[11136, 16815, 19264, 19264, 19264, 19264, 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[3921, 668, 4158, 11002, 15446, 19384, 19384, ...</td>\n",
       "      <td>[12048, 5936, 19264, 19264, 19264, 19264, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[8271, 11151, 16884, 617, 19384, 19384, 19384,...</td>\n",
       "      <td>[7372, 19264, 19264, 19264, 19264, 19264, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[13677, 722, 16875, 19384, 19384, 19384, 19384...</td>\n",
       "      <td>[2117, 12266, 19264, 19264, 19264, 19264, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[11699, 13677, 11151, 16884, 19384, 19384, 193...</td>\n",
       "      <td>[18377, 10669, 19264, 19264, 19264, 19264, 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[9923, 3921, 13677, 12470, 11176, 15446, 19384...</td>\n",
       "      <td>[12048, 5936, 19264, 19264, 19264, 19264, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[13677, 12470, 12070, 5962, 19384, 19384, 1938...</td>\n",
       "      <td>[9011, 11312, 6628, 19264, 19264, 19264, 19264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[9351, 765, 14038, 13677, 10506, 9923, 11176, ...</td>\n",
       "      <td>[2379, 19264, 19264, 19264, 19264, 19264, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[13677, 11699, 11151, 16884, 19384, 19384, 193...</td>\n",
       "      <td>[18377, 10669, 19264, 19264, 19264, 19264, 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[17054, 13677, 9923, 11176, 3921, 19384, 19384...</td>\n",
       "      <td>[12048, 5936, 19264, 19264, 19264, 19264, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[18439, 11176, 3921, 7544, 9377, 3101, 12468, ...</td>\n",
       "      <td>[13430, 19264, 19264, 19264, 19264, 19264, 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[15446, 3101, 3931, 19384, 19384, 19384, 19384...</td>\n",
       "      <td>[10668, 8098, 19264, 19264, 19264, 19264, 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[3498, 14604, 765, 9351, 3101, 10506, 19384, 1...</td>\n",
       "      <td>[14592, 19264, 19264, 19264, 19264, 19264, 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[4189, 3101, 9031, 9923, 510, 10289, 17756, 19...</td>\n",
       "      <td>[18433, 19264, 19264, 19264, 19264, 19264, 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[3101, 996, 3518, 16497, 996, 2352, 8271, 1938...</td>\n",
       "      <td>[9011, 11312, 6154, 19264, 19264, 19264, 19264...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Question  \\\n",
       "0   [3101, 1166, 3251, 9115, 19384, 19384, 19384, ...   \n",
       "1   [10446, 3101, 9565, 5034, 19384, 19384, 19384,...   \n",
       "2   [3101, 1142, 11151, 16884, 3251, 11176, 10684,...   \n",
       "3   [6069, 2830, 3101, 5034, 19384, 19384, 19384, ...   \n",
       "4   [7268, 3101, 3251, 15196, 19384, 19384, 19384,...   \n",
       "5   [14936, 617, 18495, 10684, 19384, 19384, 19384...   \n",
       "6   [3921, 668, 4158, 11002, 15446, 19384, 19384, ...   \n",
       "7   [8271, 11151, 16884, 617, 19384, 19384, 19384,...   \n",
       "8   [13677, 722, 16875, 19384, 19384, 19384, 19384...   \n",
       "9   [11699, 13677, 11151, 16884, 19384, 19384, 193...   \n",
       "10  [9923, 3921, 13677, 12470, 11176, 15446, 19384...   \n",
       "11  [13677, 12470, 12070, 5962, 19384, 19384, 1938...   \n",
       "12  [9351, 765, 14038, 13677, 10506, 9923, 11176, ...   \n",
       "13  [13677, 11699, 11151, 16884, 19384, 19384, 193...   \n",
       "14  [17054, 13677, 9923, 11176, 3921, 19384, 19384...   \n",
       "15  [18439, 11176, 3921, 7544, 9377, 3101, 12468, ...   \n",
       "16  [15446, 3101, 3931, 19384, 19384, 19384, 19384...   \n",
       "17  [3498, 14604, 765, 9351, 3101, 10506, 19384, 1...   \n",
       "18  [4189, 3101, 9031, 9923, 510, 10289, 17756, 19...   \n",
       "19  [3101, 996, 3518, 16497, 996, 2352, 8271, 1938...   \n",
       "\n",
       "                                               Answer  \n",
       "0   [2117, 12266, 19264, 19264, 19264, 19264, 1926...  \n",
       "1   [4993, 11945, 19264, 19264, 19264, 19264, 1926...  \n",
       "2   [9011, 11312, 6628, 19264, 19264, 19264, 19264...  \n",
       "3   [14837, 10292, 19264, 19264, 19264, 19264, 192...  \n",
       "4   [2117, 12266, 19264, 19264, 19264, 19264, 1926...  \n",
       "5   [11136, 16815, 19264, 19264, 19264, 19264, 192...  \n",
       "6   [12048, 5936, 19264, 19264, 19264, 19264, 1926...  \n",
       "7   [7372, 19264, 19264, 19264, 19264, 19264, 1926...  \n",
       "8   [2117, 12266, 19264, 19264, 19264, 19264, 1926...  \n",
       "9   [18377, 10669, 19264, 19264, 19264, 19264, 192...  \n",
       "10  [12048, 5936, 19264, 19264, 19264, 19264, 1926...  \n",
       "11  [9011, 11312, 6628, 19264, 19264, 19264, 19264...  \n",
       "12  [2379, 19264, 19264, 19264, 19264, 19264, 1926...  \n",
       "13  [18377, 10669, 19264, 19264, 19264, 19264, 192...  \n",
       "14  [12048, 5936, 19264, 19264, 19264, 19264, 1926...  \n",
       "15  [13430, 19264, 19264, 19264, 19264, 19264, 192...  \n",
       "16  [10668, 8098, 19264, 19264, 19264, 19264, 1926...  \n",
       "17  [14592, 19264, 19264, 19264, 19264, 19264, 192...  \n",
       "18  [18433, 19264, 19264, 19264, 19264, 19264, 192...  \n",
       "19  [9011, 11312, 6154, 19264, 19264, 19264, 19264...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_df.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class QnADataset(Dataset):\n",
    "    def __init__(self, src, trg):\n",
    "        self.src = src\n",
    "        self.trg = trg\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.src[idx], self.trg[idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the proportion of the data you want in your validation and test sets\n",
    "val_size = 0.1\n",
    "test_size = 0.1\n",
    "\n",
    "# Ensure that the validation and test set proportions sum to less than 1\n",
    "assert val_size + test_size < 1\n",
    "\n",
    "# Separate your DataFrame into two separate sets of sequences.\n",
    "src = idx_df['Question'].tolist()\n",
    "trg = idx_df['Answer'].tolist()\n",
    "\n",
    "src_vocab = question_vocab\n",
    "trg_vocab = answer_vocab\n",
    "\n",
    "src_word2index = src_vocab.word2index\n",
    "trg_word2index = trg_vocab.word2index\n",
    "\n",
    "\n",
    "# Convert words in your sequences to their corresponding indices\n",
    "src = [[src_vocab.word2index[word] if word in src_vocab.word2index else src_vocab.word2index['<UNK>'] for word in sequence] for sequence in src]\n",
    "trg = [[trg_vocab.word2index[word] if word in trg_vocab.word2index else trg_vocab.word2index['<UNK>'] for word in sequence] for sequence in trg]\n",
    "\n",
    "# Convert your sequences to PyTorch tensors\n",
    "src = [torch.tensor(item) for item in src]\n",
    "trg = [torch.tensor(item) for item in trg]\n",
    "\n",
    "# First split into train and temp sets\n",
    "src_train, src_temp, trg_train, trg_temp = train_test_split(\n",
    "    src, trg, test_size=(val_size+test_size), random_state=42)\n",
    "\n",
    "# Split the temp set into validation and test sets\n",
    "src_val, src_test, trg_val, trg_test = train_test_split(\n",
    "    src_temp, trg_temp, test_size=test_size/(val_size+test_size), random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = QnADataset(src_train, trg_train)\n",
    "val_dataset = QnADataset(src_val, trg_val)\n",
    "test_dataset = QnADataset(src_test, trg_test)\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    src, trg = zip(*batch)\n",
    "    src = torch.stack(src).permute(1, 0)\n",
    "    trg = torch.stack(trg).permute(1, 0)\n",
    "    return src, trg\n",
    "\n",
    "#ensure the dimension of the data follow the correct scheme (max_len, batch_size...)\n",
    "# Create DataLoaders for training, validation, and test sets\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Create DataLoaders for training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 64])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_dataloader))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19381\n"
     ]
    }
   ],
   "source": [
    "print(len(src_word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, embedding_size, pretrained_embeddings=None):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # self.embedding provides a vector representation of the inputs to our model\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "\n",
    "        # Load the pretrained embeddings, if available\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size)\n",
    "\n",
    "    def forward(self, i):\n",
    "\n",
    "        embedded = self.embedding(i)\n",
    "\n",
    "        o, (h, c) = self.lstm(embedded)\n",
    "\n",
    "        return o, h, c\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, embedding_size, pretrained_embeddings=None):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "\n",
    "        # self.embedding provides a vector representation of the target to our model\n",
    "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
    "\n",
    "        # Load the pretrained embeddings, if available\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size)\n",
    "\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, i, h):\n",
    "\n",
    "        embedded = self.embedding(i)\n",
    "\n",
    "        o, h = self.lstm(embedded, h)\n",
    "\n",
    "        output = self.output(o)\n",
    "\n",
    "        return output, h\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder_input_size, encoder_hidden_size, decoder_hidden_size, decoder_output_size, embedding_size, pretrained_embeddings=None):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(encoder_input_size, encoder_hidden_size, embedding_size, pretrained_embeddings)\n",
    "        self.decoder = Decoder(decoder_hidden_size, decoder_output_size, embedding_size, pretrained_embeddings)\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = trg.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output.out_features\n",
    "\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(src.device)\n",
    "\n",
    "        # Encode the input sequence\n",
    "        o, h, c = self.encoder(src)\n",
    "\n",
    "        # Initialize the decoder hidden state\n",
    "        decoder_hidden = (h.repeat(self.decoder.lstm.num_layers, 1, 1),\n",
    "                          c.repeat(self.decoder.lstm.num_layers, 1, 1))\n",
    "\n",
    "        # Set the input to the first token of the target sequence\n",
    "        input_token = trg[0, :]\n",
    "\n",
    "        for t in range(1, max_len):\n",
    "            output, decoder_hidden = self.decoder(input_token.unsqueeze(0), decoder_hidden)\n",
    "            outputs[t] = output.squeeze(0)\n",
    "\n",
    "            # Decide whether to use teacher forcing or not\n",
    "            teacher_force = torch.rand(1) < teacher_forcing_ratio\n",
    "\n",
    "            # Set the input token to either the target token or the predicted token\n",
    "            input_token = trg[t] if teacher_force else output.argmax(dim=2).squeeze(0)\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 64])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_dataloader))[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "encoder_input_size = len(src_word2index)\n",
    "encoder_hidden_size = 256\n",
    "decoder_hidden_size = 256\n",
    "decoder_output_size = len(trg_word2index)\n",
    "embedding_size = 100\n",
    "#pretrained_embeddings=None\n",
    "model = Seq2Seq(encoder_input_size, encoder_hidden_size, decoder_hidden_size, decoder_output_size, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(19381, 100)\n",
       "    (lstm): LSTM(100, 256)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(19261, 100)\n",
       "    (lstm): LSTM(100, 256)\n",
       "    (output): Linear(in_features=256, out_features=19261, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(19381, 100)\n",
       "    (lstm): LSTM(100, 256)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(19261, 100)\n",
       "    (lstm): LSTM(100, 256)\n",
       "    (output): Linear(in_features=256, out_features=19261, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for src, trg in train_loader:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        # The output dimensions are [trg len, batch size, output dim] but the loss function expects\n",
    "        # the inputs to be [batch size, output dim] and the targets to be [batch size]\n",
    "        output = output[1:].reshape(-1, output.shape[-1])\n",
    "        trg = trg[1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "    return total_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, trg in test_loader:\n",
    "            src, trg = src.to(device), trg.to(device)\n",
    "\n",
    "            output = model(src, trg, teacher_forcing_ratio=0.0)  # Disable teacher forcing during evaluation\n",
    "\n",
    "            # The output dimensions are [trg len, batch size, output dim] but the loss function expects\n",
    "            # the inputs to be [batch size, output dim] and the targets to be [batch size]\n",
    "            output = output[1:].reshape(-1, output.shape[-1])\n",
    "            trg = trg[1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [32,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [33,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [34,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [35,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [36,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [37,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [38,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [39,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [40,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [41,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [42,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [43,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [44,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [45,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [46,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [47,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [48,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [49,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [50,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [51,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [52,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [53,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [54,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [55,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [56,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [57,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [58,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [59,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [60,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [61,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [62,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "../aten/src/ATen/native/cuda/Indexing.cu:1146: indexSelectLargeIndex: block: [36,0,0], thread: [63,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_INTERNAL_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_712/20895273.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Start time for the epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_712/297630851.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# The output dimensions are [trg len, batch size, output dim] but the loss function expects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_712/3015966662.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Encode the input sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# Initialize the decoder hidden state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_712/3015966662.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    813\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    814\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR"
     ]
    }
   ],
   "source": [
    "#train with time\n",
    "# Train the model\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()  # Start time for the epoch\n",
    "\n",
    "    train_loss = train(model, train_dataloader, criterion, optimizer, device)\n",
    "    test_loss = evaluate(model, test_dataloader, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    end_time = time.time()  # End time for the epoch\n",
    "    epoch_time = end_time - start_time  # Time taken for the epoch\n",
    "\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Time: {epoch_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Training function\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Hyperparameters\n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "# Define an optimizer and a loss function (criterion)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "TRG_PAD_IDX = trg_vocab.word2index['<PAD>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "    print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
